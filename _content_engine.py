from ast import literal_eval
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.preprocessing import MultiLabelBinarizer, RobustScaler, MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import hstack


def convert_json_tags(json, key):
    """Convert JSON object into a list of strings

    Args:
        json (list): List of JSON objects.
        key (string): Name of the key which has the value.

    Returns:
        List: List of Strings.
    """

    if isinstance(json, list):
        tags = [i[key] for i in json]
        return tags
    return []


def load_data():
    """Load the dataset.
    
    Notes:
        The dataset must be tag-delimited and in UTF-8 format.

    Returns:
        DataFrame: Novel DataFrame.
    """
    
    df = pd.read_csv(r"data/novels.txt", encoding='utf-8', sep='\t', decimal=',')
    df = df.drop(columns=['novel'])
    return df

    
def clean_data(string_list):
    """Convert list of strings to lower-case and remove spaces between words.
    """
    
    if isinstance(string_list, list):
        return [str.lower(i.replace(' ', '')) for i in string_list]
    else:
        if isinstance(string_list, str):
            return str.lower(string_list.replace(' ', ''))
        else:
            return ''

    # Credit to datacamp.com/tutorial/recommender-systems-python
def weighted_rating(df, mean_rating, quantile_votes):
    """Calculate weighted rating based on IMDB's rating formula.
    
    Args:
        param1: Pandas DataFrame.
        param2: Mean rating of the votes.
        param3: The number of votes in the 90th quantile.
    
    Returns:
        int: The weighted rating.
    """
    
    vote_count = df['rating_votes']
    rating = df['rating']
    return ((vote_count / (vote_count + quantile_votes) * rating) +
            (quantile_votes / (quantile_votes + vote_count) * mean_rating)) 


    
def create_soup(df):
    """Createas a string-soup from columns in the novels dataframe.

    Args:
        df (DataFrame): Novels DataFrame with the columns 'tags', 'author', and 'fandom_tags'

    Returns:
        string: Concatenated 'soup' string of all tags, fandom_tags and author. 
    """
    
    return ' '.join(df['tags']) + ' ' + ' ' + str(df['author']) + ' ' + ' '.join(df['fandom_tags'])

#TODO: Remove all chapters under X from recommendations.
def give_recommendation(novel_id, matrix, indexes):
    """Generate a recommendation.

    Args:
        novel_id (int): The novel ID used a basis for getting the recommendation.
        matrix (kernel matrix): ndarray of shape (n_samples_X, n_samples_Y).
        indexes (Pandas Series): A Pandas Series object which have the index and the Novel ID.

    Returns:
        DataFrame: List of recommendations.
    """
    
    idx = indexes[novel_id]
    matrix_scores = list(enumerate(matrix[idx]))
    matrix_scores = sorted(matrix_scores, key=lambda x: x[1], reverse=True)
    matrix_scores = matrix_scores[1:11]
    novel_indices = [i[0] for i in matrix_scores]
    return novels_df[['novel_id', 'title', 'author', 'rating', 'weighted_rating', 'chapters', 'synopsis']].iloc[novel_indices]


def ranking(df):
    """Generate ranking based on the IMDB's rating formula for Top 250.

    Args:
        df (DataFrame): Novels DataFrame which has the columns 'rating' and 'rating_votes'
    """
    
    mean_rating = df['rating'].mean()
    quantile_votes = df['rating_votes'].quantile(0.90)
    
    df = df.copy().loc[df['rating_votes'] >= quantile_votes]
    df['weighted_rating'] = df.apply(weighted_rating, args=(mean_rating, quantile_votes, ),axis=1)
    df = df.sort_values('weighted_rating', ascending=False)
    
    print(df[['novel_id', 'title', 'rating_votes', 'rating', 'weighted_rating']].head(20))


def evaluate_engine():
    """Evaluate the recommendations generated by the engine.
    TODO

    Returns:
        None: None
    """
    return None

if __name__ == "__main__":

    novels_df = load_data()
    
    #ranking(novels_df)
    
    """Drop all novels with less than 5 chapters."""
    novels_df = novels_df[novels_df.chapters > 5].reset_index(drop=True)
    
    """Convert the JSON formatted tags, genres, fandom_tags into a list of strings."""
    features = ['tags', 'genres', 'fandom_tags']
    for feature in features:
        novels_df[feature] = novels_df[feature].apply(literal_eval)
        novels_df[feature] = novels_df[feature].apply(convert_json_tags, args=(feature, ))
        novels_df[feature] = novels_df[feature].apply(clean_data)

    novels_df['soup'] = novels_df.apply(create_soup, axis=1)

    ################################ MLB ################################
    """MLB is good for limited categorical data, such as Genres."""
    mlb = MultiLabelBinarizer()
    mlb_matrix = mlb.fit_transform(novels_df['genres'])# + novels_df['tags'])


    ############################### CV ##################################
    """CV is useful for the tags and author. This will count each occurence of a word and convert it into a matrix."""
    count = CountVectorizer(stop_words='english')
    cv_matrix = count.fit_transform(novels_df['soup'])


    ############################## TF-IDF ###############################
    """TD-IDF is the go-to-algorithm for analyzing raw text data. It takes the inverse domain frequency and converts it into a matrix."""
    tfv = TfidfVectorizer(min_df=3, 
                        max_features=None,
                        strip_accents='unicode', analyzer='word', 
                        token_pattern=r'\w{1,}',
                        ngram_range=(1,3),
                        stop_words='english')

    novels_df['synopsis'] = novels_df['synopsis'].fillna('')
    tfv_matrix = tfv.fit_transform(novels_df['synopsis'])
    
    ############################# Ratings, Views, Etc. #####################
    """Lastly we have the numerical data, such as ratings, readers, chapters, etc. Here we normalize and scale it so it fits in a 0-1 range."""
    m = novels_df['rating'].mean()
    q = novels_df['rating_votes'].quantile(0.90)

    novels_df['weighted_rating'] = novels_df.apply(weighted_rating, args=(m, q, ),axis=1)
    
    ratings = novels_df['weighted_rating'].values
    chapters = novels_df['chapters'].values
    readers = novels_df['readers'].values
    favorites = novels_df['favorites'].values
    views = novels_df['total_views_all'].values
    
    rb = RobustScaler()
    chapters = rb.fit_transform(chapters.reshape(-1, 1))
    readers = rb.fit_transform(readers.reshape(-1, 1))
    favorites = rb.fit_transform(favorites.reshape(-1, 1))
    views = rb.fit_transform(views.reshape(-1, 1))
    
    mm = MinMaxScaler(feature_range=(0,1))
    ratings = mm.fit_transform(ratings.reshape(-1, 1))
    chapters = mm.fit_transform(chapters)
    readers = mm.fit_transform(readers)
    favorites = mm.fit_transform(favorites)
    views = mm.fit_transform(views)
    
    """We stack the different matrixes from MLB, CV, TD-IDF, etc. into a collected 'feature_matrix'."""
    feature_matrix = hstack([mlb_matrix, cv_matrix, tfv_matrix, ratings, chapters, readers, favorites, views])
    
    """Calculate the cosine similarity between the different vectors in the feature_matrix. We use cosine_similarity because it is magnitude insensitive."""
    similarity_matrix = cosine_similarity(feature_matrix, feature_matrix)
    
    """
    #Just some timing functions to see what's quicker.
    start = time.time()
    similarity_matrix = sigmoid_kernel(tfv_matrix, tfv_matrix)
    stop = time.time()
    print("SIG Time: {}".format(stop-start))
    print(similarity_matrix)
     
    start = time.time()
    similarity_matrix = linear_kernel(tfv_matrix, tfv_matrix)
    stop = time.time()
    print("LK Time: {}".format(stop-start))
    print(similarity_matrix)
    
    #start = time.time()
    #similarity_matrix = cosine_similarity(tfv_matrix, tfv_matrix)
    #stop = time.time()
    #print("LK Time: {}".format(stop-start))
    #print(similarity_matrix)
    """
    
    indices = pd.Series(novels_df.index, index=novels_df['novel_id']).drop_duplicates()
    print(give_recommendation(413997, similarity_matrix, indices))
